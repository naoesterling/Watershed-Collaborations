# Unpacking and Mapping Collaboration Data: Oregon Watersheds
**Creating a Toolkit for Exploring Project-Level Data**

## Summary
The aim of this project is to provide a wide audience - citizens, policymakers, and researchers - with tools that they can use to explore, understand, and visualize data on watershed collaborations in the state of Oregon. The project’s repository contains a mix of textual data files (i.e., Microsoft Excel workbooks and CSVs), geodata files (i.e., spatial data packages), and Python scripts that were used to create an interactive map in Tableau Public. In addition to use of this map, the repository components can also be used by others together, and at times, individually to organize publicly-available collaboration data in self-designed spreadsheets as well as to create unique maps tailored to their own interests. The remainder of the sections are as follows: Section 1 contains a primer on the collaboration data engaged with in this project, Section 2 reviews the sources for the project’s data files, Section 3 describes the individual Python Scripts developed for this project, the order in which these scripts should be run in order to construct the interactive map, and the outputs of each script, Section 4 discusses the interactive map available for use on Tableau Public, and Section 5 outlines next steps for further refinement of this project and its repository.

## Section 1: An Overview of Oregon’s Approach to Collaborative Watershed Management
In 1987, the Oregon State Legislature created what is now known as the Oregon Watershed Enhancement Board (OWEB) with the aim of OWEB to facilitate and fund projects led by Oregonians (e.g., citizens, non-profits, businesses) to take care of local watershed areas and the natural resources located within them. OWEB’s vision revolves around community-level conservation, often performed through the collaboration of citizen, government, non-governmental, and private actors.
In 1997, OWEB developed the Oregon Watershed Restoration Inventory (OWRI) in which project-level data on these watershed management collaborations is recorded for projects from 1995 to 2021 (as of 5/2023). From this abundance of data, OWEB has developed an online interaction map, the Oregon Watershed Restoration Tool, that enables users to download data files. The Tool also allows individuals to filter projects by specific watershed area as well as to search for a particular project number. While helpful, the Tool’s use criteria (knowledge of watershed area designations, particular projects’ identification numbers, etc.) could pose difficulties to users in engaging with the Tool, and by extension, accessing the data it contains. In response to these potential barriers to data access and use, this project is designed to create useful data deliverables (e.g., spreadsheets, lists) from the collaboration data contained in the OWRI as well as to develop an alternative map tool for engagement with geographically-oriented elements of the Inventory.

## Section 2: Project Data Sources
The OWRI contains a wealth of information about each project conducted in this 26-year range, including data on the project’s location, the terrain within which it took place, the names of participants, and the goals that the collaboration sought to achieve; the OWRI Data Dictionary provides a more thorough description of the data in the Inventory.
For this repository, all necessary data downloads were retrieved from the OWRI. All data for this project is contained within two zipped files obtainable from the OWRI website (https://oregonexplorer.info/content/enhancing-watersheds-oregon?topic=56&ptopic=38#TheOWRIDatabaseandGISdata). Project geodata is contained within the zipped folder, OWRI_95_to_21.gdb. All other project data is contained within the zipped folder, OWRI_ExportToExcel_011023.

## Section 3: Running Repository Scripts and Understanding Relevant Data Inputs and Outputs
The zipped file OWRI_ExportToExcel_011023 contains large amount of information of the collaborative projects happening in Oregon watersheds. For the purposes of illustrating the repository’s use as well as for introducing users to a fairly foundational set of variables in this data, I developed scripts to create dataframes for basic attributes of each recorded project. These project attributes can be created in any order.

### Basic Project Information: proj_info.py
The proj_info.py script reads in an Excel CSV (project_info.csv) containing project IDs, project names, the watershed basin and sub-basin in which the project is located, and the years that the project was started and completed. This CSV was created by copying in the columns of interest from the larger Excel file, OwriDbExcel_1of3 located in OWRI_ExportToExcel_011023. After reading in the CSV, the script generates a dataframe containing the project characteristics mentioned above, organized by an index of project IDs. The created database will be constructed around this project ID index.

### Project Terrain Types: proj_terrains.py
The proj_terrains.py script reads in two Excel CSV containing project IDs and the terrain types in which these projects take place.  These CSVs were created by copying in the columns of interest from the larger Excel file, OwriDbExcel_1of3 located in OWRI_ExportToExcel_011023. The terrain types in this script refer to general categories of areas and activity types (e.g., fish passage, instream, wetland) in which project participants are operating. Some projects occur in areas and do activities that do not fall within a single terrain type and are thus considered by OWEB to be “combined” project types. Some of these projects are coded as “combined” while others are just included multiple times with different types. These projects are contained in one of the CSVs (comb_projects.csv). All projects, regardless of combined status are included in the other CSV (project_terrain_types.csv). To address the inconsistency in labeling among combined projects, after reading in the CSV of combined projects, the script generates a dataframe with all combined projects identified as combined. Using the other CSV, the script creates a dataframe containing only projects with one terrain type. Finally, the script creates a merged dataframe of all projects with consistent terrain type coding, a count of the number of terrain types, and a list of the different terrain types for each project. This merged dataframe is also made with the project ID index.

**Project Goal Data: proj_goals.py**
The proj_goals.py script reads in two Excel CSVs. The first file (project_goals.csv), similar to the terrain type file, contains four columns selected from OwriDbExcel_1of3 located in OWRI_ExportToExcel_011023. The first column contains the project ID and the remaining columns contain information about the goals for a project as reported by its coordinator. The second CSV file (project_info.csv) was used earlier to create the dataframe for basic project information. As some projects did not provide any goals during data collection, this file will be read in by the script in order to create a comprehensive index for the generated dataframe with project goal data. For each project, this script creates a dataframe containing the sums of goals for a project as well as a list of each individual goal. This dataframe uses project IDs as an index to allow it to be easily merged with other dataframes in order to construct a larger database. 

**Project Permit Data: proj_permits.py**
The proj_permits.py script reads in two Excel CSVs. The first file (project_permits.csv), similar to the terrain type file, contains columns selected from OwriDbExcel_1of3 located in OWRI_ExportToExcel_011023. The first column contains the project ID and the remaining columns contain information about any permits that were acquired in order for a project to be completed, as reported by its coordinator. The second CSV file (project_info.csv) was used earlier to create the dataframe for basic project information. As some projects did not report any permits during data collection, this file will be read in by the script in order to create a comprehensive index for the generated dataframe with project goal data. For each project, this script creates a dataframe containing the total number of permits for a project as well as a list of each individual permit. This dataframe uses project IDs as an index to allow it to be easily merged with other dataframes in order to construct a larger database. 

**Project Permit Data: proj_grants.py**
The proj_grants.py script reads in two Excel CSVs. The first file (project_grants.csv), similar to the terrain type file, contains columns selected from OwriDbExcel_1of3 located in OWRI_ExportToExcel_011023. The first column contains the project ID and the remaining columns contain information about any grants that were acquired by project participants for a project during its duration, as reported by its coordinator. The second CSV file (project_info.csv) was used earlier to create the dataframe for basic project information. As some projects did not report any grants during data collection, this file will be read in by the script in order to create a comprehensive index for the generated dataframe with project goal data. For each project, this script creates a dataframe containing the total number of grants for a project as well as a list of each individual grant received. This dataframe uses project IDs as an index to allow it to be easily merged with other dataframes in order to construct a larger database. 

## Stage 2: Cleaning Participant Name Data and Creating a Dataframe for Project Participants
As part of the OWRI, the names of project participants (e.g., Oregon Department of Forestry, ABC Watershed, XYZ Ranch) are recorded for each project. How these names are recorded, however, is likely to have changed over time as data input personnel differ. For example, Oregon Department of Forestry could be reported as such, as Oregon Dept. of Forestry, or as ODF, among other possibilities. These variations in participant name cause problems when trying to see if, when, and in what projects particular participants engage in over time. This issue makes studying participation over time difficult for researchers as well as makes identifying possible collaborators difficult for practitioners. To address this problem, scripts were developed to clean participant name data to identify variations in name for the same participant and then to construct a dataframe of these cleaned, standardized participant names.

### Clean Participant Names: particip_clean.py
The particip_clean.py script reads in one Excel CSV. This file (OWEB_partcipants.csv) contains columns selected from OwriDbExcel_1of3 located in OWRI_ExportToExcel_011023. The first column contains the project IDs and the remaining columns contain information about project participants that includes not only the name of each project participant, but also the sectoral type of each participant (e.g., government agency, local business).
The particip_clean.py script first standardizes participant names by eliminating extra spaces, converting a characters to lowercase, and removing punctuation. The script then standardizes common variations of frequently-found terms (i.e., corporation/corp, cooperative/coop, and department/dept). Once these common terms have been standardized, the script uses the fuzzywuzzy module in order to identify cases in which two names were input differently but may actually be the same participant engaging in different projects. The fuzzywuzzy module runs through the list of standardized participant names and compares each name to every other name in the list. It evaluates each of these comparisons for the number of characters that would need to be changed in order for the two names to be identical. Based on how many changes are needed, the module generates a similarity score for each pairing. You select a threshold score to which each pairing’s score is compared. If pairings’ similar score is above the threshold score set, the participant name and it’s possible matches are then included in an output csv file to be reviewed by you. 
### Name Review Process
**Pre-Review**
Once the output file has been created using particip_clean.py, the hard work begins. In the generated csv file, there will be two key columns. One column contains the names of participants that had an above-threshold similarity score with at least one other name in the list of names ran through the fuzzywuzzy module in particip_clean.py. The other column contains, for each name in the first, a list of the possible matches identified by the similarity score evaluation. In preparation for the manual review – the hard work – of this process, you will need to create additional columns – one titled “change_indicator” that will be used to identify different versions of names that are determined to be the same and the other titled “post-review” that contains the participant names that will be used moving forward. The names in the “post-review” column could be its original version or could altered to match another name in the list. Once these columns are created, you are ready to review the generated list. 

**Review**
Fortunately, the review process is fairly straightforward. Move down row by row through the CSV file you put together in the Pre-Review and examine the list of possible matches in relation to the name it was paired with by particip_clean.py. Depending on the data you are working with, some matches may be obvious and straightforward; similarly many non-matches are likely to be obvious, especially if the threshold similarity score is lower. Others may not be so clear. For this project, in situations where it was unclear if it a match exists, an Internet search was conducted to determine if entities (e.g., businesses, non-profit organizations) with both names existed, or if idiosyncratic input differences had occurred for the same collaborator.
If no match was detected among the possible options for a name, a 0 was input into the “change_indicator” column. If a match was detected and the initial name would be being changed, a 1 was input. If a match was detected and the initial name was the version that another name was being changed to, a 2 was input. In the event that after a cursory Internet search it was still unclear if a match was present and thus, more investigation was needed, a 3 was input into the “change_indicator” column. In the event that an initial name was coded with a 1 (i.e., was being changed to a different name), then the new version was input into the “post-review” column for that row. When 0’s or 2’s were input for an initial name, the initial name was carried over into the “post-review” column. For rows were the change indicator was a 3, the “post-review” column was left empty.

**Post-Review**
Once the review phase is complete, the CSV file should be reviewed and edited, if necessary, to contain those four columns. The script described next, particip_name_trace.py, accepts a CSV file with the name “reviewed_dups.csv”. A different file name could be used, but you must make sure to change the name of the file the script is coded to read in accordingly.

### Trace and Standardize Participant Names: particip_name_trace.py 
The particip_name_trace.py script reads in two Excel CSVs. The first file (OWEB_partcipants.csv) contains the name-related columns selected from OwriDbExcel_1of3 located in OWRI_ExportToExcel_011023. The first column contains the project IDs and the remaining columns contain information about project participants that includes not only the name of each project participant, but also the sectoral type of each participant (e.g., government agency, local business). This CSV was also read into particip_clean.py. The standardization process used in the cleaning script is once again applied in the current script in order to create a dataframe of pre-review participant names that can be matched and replaced, if necessarily, easily with values from dataframe of post-review names.
The second CSV file that is read in by particip_name_trace.py is the post-review CSV file, in this repository, titled “reviewed_dups.csv”. Prior to tracing and replacing participant names, any names in the post-review dataframe with a change indicator of 3 are dropped as these are not ready to be used yet. After dropping these rows, the dataframe is used to create a dictionary of all pre-review names with the post-review names as a definition of sorts. The script then searches through the list of initial names obtained from “OWEB_participants.csv” and for any names with a change indicator of 1 (i.e., that have a new name post-review) the initial name is replaced with an updated version that matches other entries in the data. The output of this script is thus a list of participant names that is more consistent and cohesive than the one obtained from the earlier OWRI download. In this project, approximately 300 participant names were corrected across the dataset.

### Create a Dataframe for Participant Information: particip_info.py
The particip_info.py script uses the inputs and outputs of the name cleaning and tracing scripts to create a dataframe of corrected participant names for the multi-year dataset. Once the standardized and corrected dataframe of names has been created, the script appends information about each participant’s sectoral background (e.g., state government agency, local contractor) to each of the participants names. The script ends by creating a dataframe of these name-sector-type lists for each project in the OWRI database. Project IDs are used as the index of this dataframe. With this dataframe constructed, you are now ready to construct the relational-ish database for this collaboration data.

## Stage 3: Construct Project Database
### Database Construction: create_database.py
So far, this process has created individual dataframes for each of the project aspects of interest – general characteristics, terrain types, goals, permits, grants, and participant information. In the create_database.py script, these dataframes are merged in order to create a larger, single dataframe that offers a more comprehensive understanding of each collaboration recorded in the OWRI. Running create_database.py after having run the earlier scripts in the way described will generate a dataframe that contains all prior key output dataframes merged according to the ID number of each project (the dataframe’s index). Once this dataframe is created in Python, it is written to a CSV file titled “project_database.csv for viewing and use in other mediums. One such medium is discussed in Section 4 where the interactive map tool, accessible via Tableau Public, is described.

## Section 4: Using the Interactive Map Tool
As noted earlier, the OWRI map component poses potential inaccessibility issues to its users. In an attempt to improve upon this current design, the database created via the Python scripts in this repository was uploaded into Tableau Public along with the geodata files (OWRI_95_to_21.gdb) for the projects as acquired from OWRI. The database (project_database.csv) was utilized as the logic table for the Tableau project and each of the three geodata packages (lines, points, and polygons) was subsequently joined onto this textual database. These spatial data joins allowed for the creation of map of the state of Oregon containing geographic indicators for all collaborations in the OWRI. By hovering over a particular project indicator, you and other users can see details about each project (e.g., project name, terrain type, participants, the number of goals). On the right side of the map, filters for project start year, county, terrain type, participants, grant count, and permit count are already available. Others could easily be made in order to accommodate desired search criteria. See the snapshot (map_tool_snapshot.png) for a preview of the tool’s appearance.

## Section 5: Next Steps for the Scripts and Future Developments and Ideas for the Project
This project and repository are a work in progress. While it may not be the prettiest coding, the scripts run, the database is constructed, and the map tool is created. With this being said, some immediate next steps are easily identifiable. Work will be done to improve the effectiveness and efficiency some of the scripts, particularly the ones facilitating participant name cleaning and tracing. Functions will be developed and put to good use throughout the repository. Additionally, other modules for creating similarity scores will be explored.
Beyond improving the functionality of the existing scripts, a brief list of future developments and ideas includes: (1) re-designing the filters on the interactive map tool to be easier to use; (2) integrate some additional geodata layers that might be helpful for map tool users such as watershed area boundaries, watershed council jurisdictions, and water quality data; and (3) engage in script design for potential network analysis applications among project participants.

## Thank you!
Thank you for checking out my repository! I’d love to hear from you if you have any thoughts about where to take this work next. Feel free to reach out to me at naoester@syr.edu.

